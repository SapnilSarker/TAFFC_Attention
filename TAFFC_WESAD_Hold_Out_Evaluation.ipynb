{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":1125.328601,"end_time":"2023-07-31T08:29:21.437121","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-07-31T08:10:36.108520","version":"2.4.0"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6055182,"sourceType":"datasetVersion","datasetId":3445338}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setting up the GPU","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\n# Check for GPU and set memory growth\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        print(\"GPUs are available and memory growth is set\")\n    except RuntimeError as e:\n        print(e)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T19:47:31.727234Z","iopub.execute_input":"2024-11-09T19:47:31.727507Z","iopub.status.idle":"2024-11-09T19:47:43.583195Z","shell.execute_reply.started":"2024-11-09T19:47:31.727480Z","shell.execute_reply":"2024-11-09T19:47:43.581756Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading the ECG data for all subjects","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\n# List to store individual subject DataFrames\ndata_frames = []\n\n# Iterate over the subject numbers\nfor subject_number in range(2, 18):\n    # Construct the file path for each subject\n    file_path = f'/kaggle/input/wesad-dataset/S{subject_number}_respiban.txt'\n    \n    # Check if the file exists\n    if os.path.exists(file_path):\n        # Read the file into a DataFrame\n        df = pd.read_csv(file_path, delimiter='\\t', skiprows=3, header=None)\n        # Select the first three columns\n        df_subset = df.iloc[:, 2]\n        # Append the DataFrame to the list\n        print(df_subset.shape)\n \n        df_subset.columns = [f'Subject_{subject_number}']\n        \n        data_frames.append(df_subset)\n    else:\n        print(f'File not found for subject {subject_number}')\n\n# Concatenate all DataFrames into a single DataFrame\ndata_1 = pd.concat(data_frames,axis=1)\n\n# Print the shape of the combined data\nprint(data_1.shape)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":103.251654,"end_time":"2023-07-31T08:12:29.380656","exception":false,"start_time":"2023-07-31T08:10:46.129002","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T23:15:01.449980Z","iopub.execute_input":"2024-11-09T23:15:01.450857Z","iopub.status.idle":"2024-11-09T23:16:06.326111Z","shell.execute_reply.started":"2024-11-09T23:15:01.450821Z","shell.execute_reply":"2024-11-09T23:16:06.325138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# The ECG signal required to have some modification to converting it from raw signal values to SI unit.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n# Define the constants\nchan_bit = 2 ** 16\nvcc = 3\n# Apply the equation to the dataset\ndata_wesad = data_1.applymap(lambda x: ((x / chan_bit - 0.5) * vcc) if not np.isnan(x) else np.nan)\n# Print the updated dataset\nprint(data_wesad)","metadata":{"papermill":{"duration":164.593963,"end_time":"2023-07-31T08:15:13.982459","exception":false,"start_time":"2023-07-31T08:12:29.388496","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:51:01.404122Z","iopub.execute_input":"2024-11-09T19:51:01.404488Z","iopub.status.idle":"2024-11-09T19:53:27.980049Z","shell.execute_reply.started":"2024-11-09T19:51:01.404458Z","shell.execute_reply":"2024-11-09T19:53:27.979053Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample plotting of the ECG signal","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Select the data for the first subject\nsubject_data = data_wesad.iloc[:550, 4]  # Assuming the first column represents the first subject\n\n# Create a time axis for the plot\ntime_axis = range(550)\n\n# Plot the data\nplt.plot(time_axis, subject_data)\nplt.xlabel('Time')\nplt.ylabel('Voltage(mV)')\nplt.title('Plot of First 1000 Data Points - Subject 1')\nplt.show()","metadata":{"papermill":{"duration":0.32037,"end_time":"2023-07-31T08:15:14.310302","exception":false,"start_time":"2023-07-31T08:15:13.989932","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:54:18.573586Z","iopub.execute_input":"2024-11-09T19:54:18.573984Z","iopub.status.idle":"2024-11-09T19:54:18.876705Z","shell.execute_reply.started":"2024-11-09T19:54:18.573952Z","shell.execute_reply":"2024-11-09T19:54:18.875797Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading the start and end of every session(stress/baseline) for each subjects. The file WESAD_mins.xlsx was made by the author(based on the WESAD documentation) for the simplification of the process. ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Specify the path to your .xlsx file\nfile_path = '/kaggle/input/wesad-dataset/WESAD_mins.xlsx'\n\n# Read the .xlsx file into a DataFrame\ndf = pd.read_excel(file_path)\ndf_sub = df.iloc[:, 1:]\n# Print the DataFrame\nprint(df_sub)","metadata":{"papermill":{"duration":0.463441,"end_time":"2023-07-31T08:15:14.782566","exception":false,"start_time":"2023-07-31T08:15:14.319125","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:54:23.126355Z","iopub.execute_input":"2024-11-09T19:54:23.126747Z","iopub.status.idle":"2024-11-09T19:54:23.459935Z","shell.execute_reply.started":"2024-11-09T19:54:23.126715Z","shell.execute_reply":"2024-11-09T19:54:23.459043Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Setting up the data points according to the baseline and stress time","metadata":{}},{"cell_type":"code","source":"num_intervals_base = 19\nnum_intervals_tsst = 9\n\nbase_interval = (df_sub['Base_end'] - df_sub['Base_start']) / (num_intervals_base + 1)\ntsst_interval = (df_sub['Tsst_end'] - df_sub['TSST_Start']) / (num_intervals_tsst + 1)\n\n# Create the new dataset\nnew_df = pd.DataFrame()\nnew_df['base_start'] = df_sub['Base_start']\nfor i in range(1, num_intervals_base + 1):\n    new_df[f'base_s{i}'] = df_sub['Base_start'] + i * base_interval\nnew_df['base_end'] = df_sub['Base_end']\nnew_df['tsst_start'] = df_sub['TSST_Start']\nfor i in range(1, num_intervals_tsst + 1):\n    new_df[f'tsst_s{i}'] = df_sub['TSST_Start'] + i * tsst_interval\nnew_df['tsst_end'] = df_sub['Tsst_end']\ndf_lebel=(new_df*700*60).T\n# Print the new dataset\nprint(df_lebel)","metadata":{"papermill":{"duration":0.072541,"end_time":"2023-07-31T08:15:14.863467","exception":false,"start_time":"2023-07-31T08:15:14.790926","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:54:27.876124Z","iopub.execute_input":"2024-11-09T19:54:27.877241Z","iopub.status.idle":"2024-11-09T19:54:27.930977Z","shell.execute_reply.started":"2024-11-09T19:54:27.877205Z","shell.execute_reply":"2024-11-09T19:54:27.930083Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Observing the absolute lowest session segment data points in the dataset.","metadata":{}},{"cell_type":"code","source":"min_diffs = df_lebel.diff(axis=0).abs().min()\n\n# Find the absolute lowest value among the minimum differences\nabsolute_lowest = np.floor(min_diffs.min()).astype(int)\n\n# Print the absolute lowest value\nprint(absolute_lowest)","metadata":{"papermill":{"duration":0.019262,"end_time":"2023-07-31T08:15:14.891519","exception":false,"start_time":"2023-07-31T08:15:14.872257","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:54:35.484568Z","iopub.execute_input":"2024-11-09T19:54:35.485348Z","iopub.status.idle":"2024-11-09T19:54:35.492258Z","shell.execute_reply.started":"2024-11-09T19:54:35.485309Z","shell.execute_reply":"2024-11-09T19:54:35.491246Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Slicing every subjects data of same shape to avoid the mismatch in the data point. Also setting up the label.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nsamples = []\nlebels = []\n# Iterate over the subjects\nfor subject_number in range(15):\n    # Read the first dataset for the current subject\n    df1 = data_wesad.iloc[:, subject_number] # Replace with your own file path\n    df2 = df_lebel.iloc[:,subject_number]\n    #print(subject_number)\n    indices = df2.values.astype(int).flatten()\n    # Iterate over the indices\n    for i in range(len(indices) - 1):\n        if i != 20:  # Exclude the 20th sample\n            start = indices[i]\n            end = start+absolute_lowest\n            sample = df1.iloc[start-1:end].values  # Cut the sample from the first dataset\n            sample = pd.Series(sample)\n            samples.append(sample)\n            #print(sample.shape)\n    lebel=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1]\n    lebels = lebels+lebel\n\n# Concatenate the samples along a new axis\nconcatenated = pd.concat(samples,axis=1).T\nlebel_all = pd.DataFrame(lebels)\n\n# Print the shape of the concatenated dataset\nprint(concatenated.shape)\nprint(lebel_all.shape)","metadata":{"papermill":{"duration":0.132122,"end_time":"2023-07-31T08:15:15.032213","exception":false,"start_time":"2023-07-31T08:15:14.900091","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:54:40.283221Z","iopub.execute_input":"2024-11-09T19:54:40.283556Z","iopub.status.idle":"2024-11-09T19:54:40.397996Z","shell.execute_reply.started":"2024-11-09T19:54:40.283522Z","shell.execute_reply":"2024-11-09T19:54:40.397056Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Downsamplin the dataset from (700 Hz to 256 Hz to reduce the computationl cost and the improvement of the performance","metadata":{"papermill":{"duration":0.008332,"end_time":"2023-07-31T08:15:15.049137","exception":false,"start_time":"2023-07-31T08:15:15.040805","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import numpy as np\nfrom scipy.signal import resample\noriginal_dataset = concatenated.T\n\n# Assuming original_dataset has shape (450, 40608)\ndownsampled_dataset = np.zeros((450, 256 * (40608 // 700)))  # Downsampling to 256 Hz\nprint(original_dataset[0].shape)\nfor i in range(original_dataset.shape[1]):\n    original_signal = original_dataset[i]\n    downsampled_signal = resample(original_signal, 256 * (40608 // 700))\n    downsampled_dataset[i, :] = downsampled_signal\nwesad_x=downsampled_dataset.T\nprint(wesad_x.shape)  # Output: (90, 58418)","metadata":{"execution":{"iopub.status.busy":"2024-11-09T19:54:46.661847Z","iopub.execute_input":"2024-11-09T19:54:46.662558Z","iopub.status.idle":"2024-11-09T19:54:47.408047Z","shell.execute_reply.started":"2024-11-09T19:54:46.662520Z","shell.execute_reply":"2024-11-09T19:54:47.406887Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Observing the downsampled dataset.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Select the data for the first subject\nwesad_x = pd.DataFrame(wesad_x)\nsubject_data = wesad_x.iloc[:2000, 4]  # Assuming the first column represents the first subject\n\n# Create a time axis for the plot\ntime_axis = range(2000)\n\n# Plot the data\nplt.plot(time_axis, subject_data)\nplt.xlabel('Time')\nplt.ylabel('Voltage(mV)')\nplt.title('Plot of First 1000 Data Points - Subject 1')\nplt.show()","metadata":{"papermill":{"duration":0.28186,"end_time":"2023-07-31T08:15:15.398874","exception":false,"start_time":"2023-07-31T08:15:15.117014","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:54:50.709240Z","iopub.execute_input":"2024-11-09T19:54:50.709998Z","iopub.status.idle":"2024-11-09T19:54:50.959843Z","shell.execute_reply.started":"2024-11-09T19:54:50.709962Z","shell.execute_reply":"2024-11-09T19:54:50.958924Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transposing the dataset.","metadata":{}},{"cell_type":"code","source":"X= wesad_x.T\ny=lebel_all\nprint(y.shape)","metadata":{"papermill":{"duration":0.020623,"end_time":"2023-07-31T08:15:31.336188","exception":false,"start_time":"2023-07-31T08:15:31.315565","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:54:57.548930Z","iopub.execute_input":"2024-11-09T19:54:57.549228Z","iopub.status.idle":"2024-11-09T19:54:57.554687Z","shell.execute_reply.started":"2024-11-09T19:54:57.549202Z","shell.execute_reply":"2024-11-09T19:54:57.553739Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Slicing the dataset for making 10 sec. non-overlapping samples.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Assuming X is your DataFrame with shape (450, 14848)\n# Split the DataFrame into two halves along the columns\nfirst = X.iloc[:, :2475]\nfirst1 = X.iloc[:, 2474:4949]\nsecond = X.iloc[:, 4949:7424]\nsecond1 = X.iloc[:, 7423:9898]\nthird = X.iloc[:, 9898:12373]\nthird1 = X.iloc[:, 12372:14847]\n\n# Convert to NumPy arrays for stacking\nfirst_half_np = first.to_numpy()\nsecond_half_np = second.to_numpy()\nthird_half_np = third.to_numpy()\nfirst_half_np1 = first1.to_numpy()\nsecond_half_np1 = second1.to_numpy()\nthird_half_np1 = third1.to_numpy()\n# Stack the two halves along the rows\nresult = np.vstack((first_half_np, first_half_np1, second_half_np,second_half_np1, third_half_np,  third_half_np1))\n\n# Verify the shape of the resulting array\nprint(result.shape)  # This should print (900, 7424)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-09T19:55:00.805078Z","iopub.execute_input":"2024-11-09T19:55:00.805476Z","iopub.status.idle":"2024-11-09T19:55:00.832634Z","shell.execute_reply.started":"2024-11-09T19:55:00.805432Z","shell.execute_reply":"2024-11-09T19:55:00.831707Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Also setting the label for 10 sec. segments.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nrepeated_y = np.tile(y, (6, 1))\n\n# Verify the shape of the resulting array\nprint(repeated_y.shape) ","metadata":{"execution":{"iopub.status.busy":"2024-11-09T19:55:04.789293Z","iopub.execute_input":"2024-11-09T19:55:04.789659Z","iopub.status.idle":"2024-11-09T19:55:04.795093Z","shell.execute_reply.started":"2024-11-09T19:55:04.789627Z","shell.execute_reply":"2024-11-09T19:55:04.794053Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Simple preprocessing with standard scaler, splitting the dataset into test and train subset. Observing the majority and minority class in the train dataset. ","metadata":{"papermill":{"duration":0.009902,"end_time":"2023-07-31T08:15:31.356218","exception":false,"start_time":"2023-07-31T08:15:31.346316","status":"completed"},"tags":[]}},{"cell_type":"code","source":"features=result\nlabels=repeated_y\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\n# Assuming filtered_data and repeated_y (as y) are already defined\nX_train, X_test, y_train, y_test = train_test_split(features, repeated_y, test_size=0.3, shuffle=True, stratify=repeated_y)\n\n# Scaling the data\nscaling = StandardScaler()\nX_train = scaling.fit_transform(X_train)\nX_test = scaling.transform(X_test)\n\n# Reshape y_train and y_test to 1D arrays for proper indexing\ny_train = y_train.ravel()\ny_test = y_test.ravel()\n\n# Select majority and minority classes\nX_majority = X_train[y_train == 0]\nX_minority = X_train[y_train == 1]\n\nprint(X_minority.shape)\nprint(X_majority.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-09T19:55:08.468893Z","iopub.execute_input":"2024-11-09T19:55:08.469284Z","iopub.status.idle":"2024-11-09T19:55:08.732569Z","shell.execute_reply.started":"2024-11-09T19:55:08.469251Z","shell.execute_reply":"2024-11-09T19:55:08.731592Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Minority data augmentaion using shifting method.","metadata":{}},{"cell_type":"code","source":"X_minority_augmented = np.zeros((2*X_minority.shape[0], 2304))\nprint(X_minority_augmented.shape)\nj=0\ni=0\n#print(int(X_minority.shape[0]/2))\nfor i in range(int(X_minority.shape[0]/2)):\n    i = i*2\n    #print(i)\n    x1=X_minority[i,:]\n    x2=X_minority[i+1,:]\n    x_combined = np.concatenate((X_minority[i,:], X_minority[i+1,:]))\n    #print(x_combined.shape)\n    x3 = x_combined[768:3072]\n    x4 = x_combined[1792:4096]\n    #print(x3.shape)\n    #print(x2.shape)\n        \n    X_minority_augmented[j] = x1  #np.roll(x1, 2000)\n    j=j+1    \n    X_minority_augmented[j] = x2  #np.roll(x1, 2000)\n    j=j+1\n    X_minority_augmented[j] = x3  #np.roll(x1, 2000)\n    j=j+1\n    #x1=X_minority[i,:]\n    X_minority_augmented[j] = x4 #np.roll(x1, 2000)x1\n    j=j+1\n    #i=i+1\n    #print(i)\n#print(i)\nprint(X_minority_augmented.shape)\nX_train_augmented = np.vstack((X_majority, X_minority_augmented))\ny_train_augmented = np.hstack((np.zeros(X_majority.shape[0]), np.ones(X_minority_augmented.shape[0])))\n# shuffle the data\n\nidx = np.random.permutation(X_train_augmented.shape[0])\n#print(idx)\nX_train_augmented = X_train_augmented[idx]\ny_train_augmented = pd.DataFrame(y_train_augmented[idx])\nprint(X_train_augmented.shape)\n#print(y_train_augmented[0])\nX_train=X_train_augmented\ny_train=y_train_augmented","metadata":{"papermill":{"duration":0.166918,"end_time":"2023-07-31T08:15:33.686913","exception":false,"start_time":"2023-07-31T08:15:33.519995","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T19:55:14.166295Z","iopub.execute_input":"2024-11-09T19:55:14.166663Z","iopub.status.idle":"2024-11-09T19:55:14.244861Z","shell.execute_reply.started":"2024-11-09T19:55:14.166632Z","shell.execute_reply":"2024-11-09T19:55:14.243727Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Proposed model architecture.","metadata":{"papermill":{"duration":0.010737,"end_time":"2023-07-31T08:15:33.708213","exception":false,"start_time":"2023-07-31T08:15:33.697476","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Bidirectional, Dense, Dropout, BatchNormalization, GlobalMaxPooling1D, Attention, Concatenate\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.regularizers import l2\n\ninput_layer = Input(shape=(2475, 1))\n\n# Shared CNN layers\ndef shared_cnn(input_layer, filters1, kernel_size1, filters2, kernel_size2, filters3, kernel_size3):\n    conv1 = Conv1D(filters=filters1, kernel_size=kernel_size1, activation='relu')(input_layer)\n    maxpool1 = MaxPooling1D(pool_size=2)(conv1)\n    batch_norm1 = BatchNormalization()(maxpool1)\n\n    conv2 = Conv1D(filters=filters2, kernel_size=kernel_size2, activation='relu')(batch_norm1)\n    maxpool2 = MaxPooling1D(pool_size=2)(conv2)\n    batch_norm2 = BatchNormalization()(maxpool2)\n\n    conv3 = Conv1D(filters=filters3, kernel_size=kernel_size3, activation='relu')(batch_norm2)\n    maxpool3 = MaxPooling1D(pool_size=2)(conv3)\n    batch_norm3 = BatchNormalization()(maxpool3)\n\n    return batch_norm3\n\n# Shared BiLSTM layer with attention\ndef shared_bilstm_with_attention(shared_cnn_output, units, return_sequences, num_heads):\n    bilstm_output = Bidirectional(LSTM(units=units, return_sequences=return_sequences))(shared_cnn_output)\n    attention_heads = []\n    for _ in range(num_heads):\n        attention_head = Attention()([bilstm_output, bilstm_output])\n        attention_heads.append(attention_head)\n\n    # Concatenate the outputs of attention heads\n    multi_attention = Concatenate(axis=-1)(attention_heads)\n    global_pool = GlobalMaxPooling1D()(bilstm_output)\n    return global_pool\n\n# Apply shared CNN and BiLSTM with attention to each input path with different parameters\nshared_cnn_output1 = shared_cnn(input_layer, filters1=64, kernel_size1=10, filters2=128, kernel_size2=5, filters3=256, kernel_size3=3)\nshared_bilstm_output1 = shared_bilstm_with_attention(shared_cnn_output1, units=64, return_sequences=True, num_heads=4)\n\nshared_cnn_output2 = shared_cnn(input_layer, filters1=32, kernel_size1=14, filters2=64, kernel_size2=8, filters3=128, kernel_size3=5)\nshared_bilstm_output2 = shared_bilstm_with_attention(shared_cnn_output2, units=32, return_sequences=True, num_heads=2)\n\n# Concatenate the outputs of both paths\nconcatenated_output = Concatenate(axis=-1)([shared_bilstm_output1, shared_bilstm_output2])\n#with kernel size 14, cnn, bilstm\n# Dense layers\nglobal_pool2 = GlobalMaxPooling1D()(shared_cnn_output2)\nglobal_pool1 = GlobalMaxPooling1D()(shared_cnn_output1)\nconcatenated_output2 = Concatenate(axis=-1)([global_pool1, global_pool2])\n\ndense1 = Dense(units=256, activation='relu', kernel_regularizer=l2(0.01))(shared_bilstm_output2)\nbatch_norm4 = BatchNormalization()(dense1)\ndrop1 = Dropout(0.4)(batch_norm4)\n\ndense2 = Dense(units=128, activation='relu', kernel_regularizer=l2(0.01))(drop1)\nbatch_norm5 = BatchNormalization()(dense2)\ndrop2 = Dropout(0.4)(batch_norm5)\n\n# Output layer\noutput = Dense(units=1, activation='sigmoid')(drop2)\n\n# Model\nmodel = Model(inputs=input_layer, outputs=output)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"papermill":{"duration":12.040999,"end_time":"2023-07-31T08:15:45.759622","exception":false,"start_time":"2023-07-31T08:15:33.718623","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T22:29:06.455955Z","iopub.execute_input":"2024-11-09T22:29:06.456792Z","iopub.status.idle":"2024-11-09T22:29:07.760305Z","shell.execute_reply.started":"2024-11-09T22:29:06.456758Z","shell.execute_reply":"2024-11-09T22:29:07.759466Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training the model.","metadata":{"papermill":{"duration":0.01437,"end_time":"2023-07-31T08:15:45.789268","exception":false,"start_time":"2023-07-31T08:15:45.774898","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\n# Define early stopping and checkpoint callbacks\nes = EarlyStopping(monitor='val_loss', mode='min', patience=30)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n\n# Train the model with early stopping and checkpoint callbacks\nhistory = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), callbacks=[es, mc])","metadata":{"papermill":{"duration":799.34622,"end_time":"2023-07-31T08:29:05.149902","exception":false,"start_time":"2023-07-31T08:15:45.803682","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-09T23:17:33.700468Z","iopub.execute_input":"2024-11-09T23:17:33.700841Z","iopub.status.idle":"2024-11-09T23:17:46.676611Z","shell.execute_reply.started":"2024-11-09T23:17:33.700810Z","shell.execute_reply":"2024-11-09T23:17:46.675079Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculating the confusion matrix","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom keras.models import load_model\n# Load the saved model\nmodel = load_model('best_model.h5')\n\n# Predict the class probabilities for the test set\ny_pred = model.predict(X_test)\n\n# Convert the probabilities into class labels using a threshold of 0.5\ny_pred_classes = (y_pred > 0.5).astype(int)\n\n# Calculate the confusion matrix\ncm = confusion_matrix(y_test, y_pred_classes)\nprint(cm)","metadata":{"papermill":{"duration":8.391138,"end_time":"2023-07-31T08:29:13.721771","exception":false,"start_time":"2023-07-31T08:29:05.330633","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plotting the Loss vs Epoch curve","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\n\n# Print loss vs. epoch curve\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":0.457886,"end_time":"2023-07-31T08:29:14.359836","exception":false,"start_time":"2023-07-31T08:29:13.901950","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculating the AUC score","metadata":{}},{"cell_type":"code","source":"# Calculate predictions for the test set\ny_pred = model.predict(X_test)\n\n# Calculate AUC score\nauc_score = roc_auc_score(y_test, y_pred)\n\n# Print AUC score\nprint('AUC Score:', auc_score)","metadata":{"papermill":{"duration":1.561711,"end_time":"2023-07-31T08:29:16.101784","exception":false,"start_time":"2023-07-31T08:29:14.540073","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plotting the ROC curve.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_curve, roc_auc_score\n\n# Calculate predictions for the test set\ny_pred = model.predict(X_test)\n\n# Calculate false positive rate, true positive rate, and thresholds\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\n\n# Calculate AUC score\nauc_score = roc_auc_score(y_test, y_pred)\n\n# Plot ROC curve\nplt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(auc_score))\nplt.plot([0, 1], [0, 1], linestyle='--', color='r', label='Random')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend()\nplt.show()","metadata":{"papermill":{"duration":1.82257,"end_time":"2023-07-31T08:29:18.106251","exception":false,"start_time":"2023-07-31T08:29:16.283681","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature Maps for 2 example showing seperately.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\n\n# Assuming 'X_test' is your test data and 'model' is your trained model\n\n# Specify the layers for which you want to visualize the feature maps\nconv_layers = ['conv1d_3']  # Replace with actual layer names\n\n# Create a new model that outputs the activations of the specified layers\nlayer_outputs = [model.get_layer(layer_name).output for layer_name in conv_layers]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\n\n# Number of examples you want to visualize\nnum_examples = 10  # You can change this to the number of examples you want to visualize\n\n# Generate and visualize feature maps for example 1 and example 6\nexamples_to_visualize = [12,16]\n\nfor i in examples_to_visualize:\n    input_tensor = tf.convert_to_tensor(X_test[i:i+1], dtype=tf.float32)\n    true_class = y_test[i]  # Get the true class label for the example\n    \n    # Get the feature maps\n    activations = activation_model.predict(input_tensor)\n    \n    # Get the predicted class\n    prediction = model.predict(input_tensor)\n    predicted_class = int(prediction > 0.5)  # Assuming binary classification with sigmoid\n\n    # Define title color based on the true class\n    title_color = 'purple' if true_class == 0 else 'orange'\n\n    for layer_name, activation in zip(conv_layers, activations):\n        num_filters = activation.shape[-1]\n        num_cols = 8  # Number of columns for subplot\n        num_rows = (num_filters + num_cols - 1) // num_cols  # Calculate number of rows needed\n\n        plt.figure(figsize=(15, num_rows * 2))\n        for j in range(num_filters):\n            plt.subplot(num_rows, num_cols, j + 1)\n            plt.plot(activation[:, j])  # Corrected indexing for 2D array\n            plt.title(f'Filter {j}')\n            plt.axis('off')\n        plt.suptitle(\n            f'Example {i+1} - True Class: {true_class} - Predicted Class: {predicted_class} - Feature maps for layer: {layer_name}', \n            fontsize=16, color=title_color\n        )\n        plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make room for the title\n        plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Feature maps of 2 example showing side by side. ","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Model\n\n# Assuming 'X_test' is your test data and 'model' is your trained model\n\n# Specify the layers for which you want to visualize the feature maps\nconv_layers = ['conv1d_3']  # Replace with actual layer names\n\n# Create a new model that outputs the activations of the specified layers\nlayer_outputs = [model.get_layer(layer_name).output for layer_name in conv_layers]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\ncolors = ['blue', 'red']\n# Indices of the examples you want to visualize\nexamples_to_visualize = [12, 16]\n\n# Ensure the selected examples exist in the dataset\nif max(examples_to_visualize) >= len(X_test):\n    raise ValueError(\"Example index out of range\")\n\n# Generate and visualize feature maps for the specified convolutional layer\nfor layer_name in conv_layers:\n    # Collect activations for both examples\n    activations = []\n    for i in examples_to_visualize:\n        input_tensor = tf.convert_to_tensor(X_test[i:i+1], dtype=tf.float32)\n        activation = activation_model.predict(input_tensor)\n        activations.append(activation[0])  # Extract the first (and only) batch element\n    \n    num_filters = activations[0].shape[-1]\n    num_cols = 16  # Number of columns for subplot\n    num_rows = (num_filters + num_cols - 1) // num_cols * len(examples_to_visualize)  # Calculate rows needed\n\n    plt.figure(figsize=(24, num_rows * 2))\n    for j in range(num_filters):\n        for k, activation in enumerate(activations):\n            plt.subplot(num_rows, num_cols, j * len(examples_to_visualize) + k + 1)\n            plt.plot(activation[:, j], color=colors[k])\n            if k == 0:\n                plt.title(f'                     Filter {j}',fontsize = 16)\n            plt.axis('off')\n    plt.suptitle(\n        f'Feature Maps for Layer: {layer_name} - True Positive (Ex. {examples_to_visualize[0]+1}) Vs True Negative (Ex. {examples_to_visualize[1]+1})', \n        fontsize=24\n    )\n    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make room for the title : Ex. {examples_to_visualize[0]} Vs Ex. {examples_to_visualize[1]}\n    plt.savefig('Feature_mapping_conv1d_3_wesad.png') \n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Defining the function of UMAP","metadata":{}},{"cell_type":"code","source":"pip install umap-learn","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nimport numpy as np\nimport umap\nimport matplotlib.pyplot as plt\nimport umap.umap_ as umap\nfrom tensorflow.keras.models import load_model\n\n# Assuming 'model' is your Keras model\nfor layer in model.layers:\n    print(layer.name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embeddign representation for raw ECG signals. ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'input_layer'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Rep. of Test Data')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_maps1.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embedding representation of batch_normalization_2 (3rd cnn of block 1) layer embedding.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'batch_normalization_2'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Features Rep. of CNN Layers')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_cnn1.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embedding representation of batch_normalization_5 (3rd cnn of block 2) layer embedding","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'batch_normalization_5'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Features Rep. of CNN Layers')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_cnn2.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embedding representation of bilstm(bilstm of block 1) layer embeddingÂ¶","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'bidirectional'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Features Rep. of BiLSTM Layer')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_bilstm1.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embedding representation of bilstm(bilstm of block 2) layer embedding","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'bidirectional_1'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Features Rep. of BiLSTM Layer')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_bilstm2.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embedding representation of attention mechanism (block 1) layer embedding","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'concatenate'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Features Rep. of MHA Layer')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_attention1.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embedding representation of bilstm (block 1) layer embedding","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'concatenate_1'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Features Rep. of MHA Layer')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_attention2.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# UMAP Embedding representation of dropout_1 (output block dense layer 2) layer embedding","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\nimport umap\n\n# Specify the layer name\nlayer_name = 'dropout_1'  # Replace with your actual layer name\n\n# Create a new model that outputs the activations of the specified layer\nlayer_output = model.get_layer(layer_name).output\nactivation_model = Model(inputs=model.input, outputs=layer_output)\n\n# Get feature maps for all test data\nfeature_maps = activation_model.predict(X_test)\n# Flatten feature maps to 2D array (samples, features)\nnum_samples = feature_maps.shape[0]\nnum_features = np.prod(feature_maps.shape[1:])  # Flatten all dimensions except the batch dimension\nflattened_feature_maps = feature_maps.reshape(num_samples, num_features)\n\n# Run UMAP to reduce to 2D\nreducer = umap.UMAP(n_components=2, random_state=42)\numap_embedding = reducer.fit_transform(flattened_feature_maps)\n\n\n# Assuming you have true positive and true negative labels\ntp_indices = np.where(y_test == 1)[0]\ntn_indices = np.where(y_test == 0)[0]\n\nplt.figure(figsize=(5, 4))\nplt.scatter(umap_embedding[tp_indices, 0], umap_embedding[tp_indices, 1], color='red', label='Positives', s=10)\nplt.scatter(umap_embedding[tn_indices, 0], umap_embedding[tn_indices, 1], color='blue', label='Negatives', s=10)\nplt.title(f'UMAP Features Rep. of Dense Layer 2')\nplt.xlabel('UMAP 1')\nplt.ylabel('UMAP 2')\nplt.legend()\n# Save the plot as an image file\nplt.savefig('umap_feature_dense2.png')  # You can change the filename and format as needed\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}